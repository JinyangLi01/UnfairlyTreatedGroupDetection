{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from Algorithms import pattern_count\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def generateTuple(original_data):\n",
    "    describe_data = original_data.describe()\n",
    "    attributes = original_data.columns.tolist()\n",
    "    tuple = list()\n",
    "    for att in attributes:\n",
    "        if att == 'score':\n",
    "            min = (describe_data[att]['min'])\n",
    "            max = (describe_data[att]['max'])\n",
    "            a = random.uniform(min, max)\n",
    "            tuple.append(a)\n",
    "        else:\n",
    "            min = int(describe_data[att]['min'])\n",
    "            max = int(describe_data[att]['max'])\n",
    "            a = random.randint(min, max)\n",
    "            tuple.append(a)\n",
    "    return tuple\n",
    "\n",
    "def extendDataset(newsize, filepath, output_pre):\n",
    "    global tp\n",
    "    original_data = pd.read_csv(filepath)\n",
    "\n",
    "    original_data_pc = pattern_count.PatternCounter(original_data, encoded=False)\n",
    "    original_data_pc.parse_data()\n",
    "\n",
    "    oldsize = len(original_data)\n",
    "    num_new_tuples = newsize - oldsize\n",
    "    print(num_new_tuples)\n",
    "    for i in range(num_new_tuples):\n",
    "        tp = generateTuple(original_data)\n",
    "        original_data.loc[len(original_data)] = tp\n",
    "        if i % 1000 == 0:\n",
    "            print(i, tp)\n",
    "    output_path = output_pre + str(newsize) + \".csv\"\n",
    "    original_data.to_csv(output_path, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "def UpdateAndRank(file_path, ranked_by):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['rank'] = data[ranked_by].rank(method='first', na_option='bottom', ascending=False)\n",
    "    data = data.sort_values(by='rank', ascending=True)\n",
    "    data.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "def ExtendAndRank(size, input_file_path, output_pre, ranked_by_att):\n",
    "    extendDataset(size, input_file_path, output_pre)\n",
    "    new_file_path = output_pre + str(size) + '.csv'\n",
    "    UpdateAndRank(new_file_path, ranked_by_att)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# UpdateAndRank(\"../../InputData/StudentDataset/LargeDatasets/400.csv\", 'G3')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#input_file_path = \"../../InputData/StudentDataset/LargeDatasets/1100.csv\"\n",
    "#output_pre = r\"../../InputData/StudentDataset/LargeDatasets/\"\n",
    "#ExtendAndRank(1200, input_file_path, output_pre, 'G3')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "all_attributes = [\"age_binary\",\"sex_binary\",\"race_C\",\"MarriageStatus_C\",\"juv_fel_count_C\",\n",
    "                  \"decile_score_C\", \"juv_misd_count_C\",\"juv_other_count_C\",\"priors_count_C\",\"days_b_screening_arrest_C\",\n",
    "                  \"c_days_from_compas_C\",\"c_charge_degree_C\",\"v_decile_score_C\",\"start_C\",\"end_C\",\n",
    "                  \"event_C\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0 [0, 1, 1, 0, 0.9121961929477572, 2131, 1, 1, 1, 2, 2, 1, 2, 0, 1, 0, 0, 0, 6, 0, 1, 0, -3, -2]\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"../../InputData/CompasData/ForRanking/LargeDatasets/7000.csv\"\n",
    "output_pre = r\"../../InputData/CompasData/ForRanking/LargeDatasets/\"\n",
    "ExtendAndRank(8000, input_file_path, output_pre, 'score')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "1000\n",
      "0 [1, 0, 1, 1, 1.506149645567406, 3253, 1, 0, 0, 1, 2, 0, 2, 0, 1, 1, 0, 1, 6, 1, 0, 1, -3, 0]\n",
      "9000\n",
      "1000\n",
      "0 [0, 0, 0, 0, 1.3413694283859048, 8456, 3, 0, 1, 0, 3, 0, 2, 1, 0, 1, 2, 1, 1, 1, 1, 1, -2, 0]\n",
      "10000\n",
      "1000\n",
      "0 [0, 0, 0, 0, -0.25427282636022797, 9405, 2, 1, 2, 2, 0, 0, 1, 0, 0, 1, 2, 1, 5, 0, 1, 0, 0, 0]\n",
      "11000\n",
      "1000\n",
      "0 [1, 0, 0, 0, 0.8355607146330807, 9829, 3, 1, 2, 2, 0, 0, 1, 1, 1, 1, 2, 1, 3, 1, 0, 0, -2, 0]\n",
      "12000\n",
      "1000\n",
      "0 [0, 1, 0, 2, 1.8200607904484896, 3262, 0, 0, 1, 0, 2, 2, 0, 0, 0, 2, 2, 0, 1, 0, 0, 1, -2, -3]\n",
      "13000\n",
      "1000\n",
      "0 [0, 0, 0, 0, -0.30727646069998815, 5273, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, -4, -2]\n",
      "14000\n",
      "1000\n",
      "0 [0, 1, 1, 1, 1.5367806851308883, 6729, 2, 0, 2, 2, 2, 1, 2, 0, 1, 2, 0, 0, 5, 0, 1, 1, -1, 0]\n",
      "15000\n",
      "1000\n",
      "0 [1, 0, 1, 1, -0.2546084293668581, 7580, 1, 0, 2, 0, 2, 2, 2, 1, 1, 2, 0, 0, 4, 0, 1, 0, -4, -3]\n",
      "16000\n",
      "1000\n",
      "0 [0, 0, 0, 1, -0.033848996648973007, 7742, 1, 0, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 6, 0, 1, 0, -3, -3]\n",
      "17000\n",
      "1000\n",
      "0 [1, 1, 1, 1, 1.1041242221208338, 15139, 3, 0, 1, 0, 2, 2, 0, 0, 0, 2, 1, 0, 4, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(8000, 18000, 1000):\n",
    "    print(i)\n",
    "    output_pre = r\"../../InputData/CompasData/ForRanking/LargeDatasets/\"\n",
    "    input_file_path = \"../../InputData/CompasData/ForRanking/LargeDatasets/\" + str(i) + \".csv\"\n",
    "    ExtendAndRank(i+1000, input_file_path, output_pre, 'score')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}